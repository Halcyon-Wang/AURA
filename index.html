<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AURA 16.5 — The Synchronized Field</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <style>
        /* Typography & Jil Sander Aesthetic */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@200;300;400&display=swap');

        :root {
            --bg-jil-sander: #F7F6F2;
            --ui-base-color: #EAEAEA;
            --ui-border-color: rgba(234, 234, 234, 0.2);
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
            user-select: none;
        }

        body,
        html {
            width: 100%;
            height: 100%;
            overflow: hidden;
            background: var(--bg-jil-sander);
            font-family: 'Inter', sans-serif;
            font-weight: 300;
            letter-spacing: 0.1em;
            -webkit-font-smoothing: antialiased;
        }

        body.cursor-hidden,
        body.cursor-hidden * {
            cursor: none !important;
        }

        /* Background Canvas Layer */
        #canvas-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
            opacity: 0;
            transition: opacity 1.5s cubic-bezier(0.25, 0.1, 0.25, 1);

            /* --- CRITICAL: THE OPTICAL CAMOUFLAGE --- */
            background-color: #000000;
        }

        #canvas-container.revealed {
            opacity: 1;
        }

        /* UI Overlay Layer - Utilizing Optical Blending */
        #ui-layer {
            position: relative;
            z-index: 10;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            padding: 4vh 4vw;
            pointer-events: none;
            color: var(--ui-base-color);
            mix-blend-mode: difference;
        }

        /* Header Architecture */
        header {
            font-size: 11px;
            text-transform: uppercase;
            letter-spacing: 0.3em;
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            pointer-events: auto;
        }

        .brand {
            font-weight: 400;
        }

        .brand span {
            opacity: 0.5;
            margin-left: 16px;
            font-weight: 200;
        }

        .top-right-cluster {
            display: flex;
            align-items: center;
            /* Forces perfect horizontal center alignment */
            justify-content: flex-end;
            gap: 16px;
            /* Mathematical spacing */
        }

        .track-name {
            font-size: 11px;
            font-weight: 400;
            /* Ensure this matches your global typography */
            letter-spacing: 0.1em;
            text-transform: uppercase;
            line-height: 1;
            color: inherit;
            transition: opacity 0.5s ease;
        }

        .icon-btn {
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            opacity: 0.6;
            /* Subtle hierarchy */
            transition: opacity 0.4s ease;
        }

        .icon-btn:hover {
            opacity: 1.0;
        }

        .icon-btn svg {
            width: 12px;
            /* Matched exactly to the x-height/cap-height of 11px font */
            height: 12px;
            fill: currentColor;
            /* Inherits the exact color of the text */
        }

        /* Cinematic Export Tally Light */
        @keyframes cinematic-blink {
            0% {
                opacity: 1;
            }

            50% {
                opacity: 0.3;
            }

            100% {
                opacity: 1;
            }
        }

        .tally-light {
            display: none;
            /* Hidden by default */
            width: 4px;
            height: 4px;
            border-radius: 50%;
            background-color: #ff3333;
            margin-left: 12px;
            animation: cinematic-blink 1.5s infinite ease-in-out;
        }

        .tally-light.recording {
            display: block;
        }

        /* Injection Zone */
        #drop-zone {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            text-align: center;
            cursor: pointer;
            pointer-events: auto;
            transition: opacity 0.8s ease, transform 0.8s ease;
        }

        #drop-zone input {
            display: none;
        }

        .play-btn-large {
            font-size: 11px;
            text-transform: uppercase;
            letter-spacing: 0.4em;
            padding: 18px 40px;
            border: 1px solid var(--ui-base-color);
            background: transparent;
            color: var(--ui-base-color);
            transition: all 0.3s ease;
        }

        #drop-zone:hover .play-btn-large {
            background: var(--ui-base-color);
            color: #000;
        }

        /* Footer Architecture */
        footer {
            display: flex;
            align-items: center;
            gap: 3vw;
            font-size: 10px;
            opacity: 0;
            transform: translateY(15px);
            transition: all 1.2s ease;
            pointer-events: auto;
            width: 100%;
            text-transform: uppercase;
            letter-spacing: 0.15em;
        }

        .btn-container {
            width: 60px;
            flex-shrink: 0;
        }

        .btn {
            background: none;
            border: none;
            color: inherit;
            font-family: inherit;
            font-size: 10px;
            text-transform: uppercase;
            cursor: pointer;
            opacity: 0.5;
            transition: opacity 0.2s;
            letter-spacing: 0.15em;
            width: 100%;
            text-align: left;
        }

        .btn:hover {
            opacity: 1;
        }

        .progress-container {
            flex-grow: 1;
            height: 24px;
            display: flex;
            align-items: center;
            cursor: pointer;
            position: relative;
        }

        .progress-bg {
            width: 100%;
            height: 1px;
            background: var(--ui-border-color);
            position: relative;
        }

        .progress-bar {
            height: 100%;
            width: 0%;
            background: var(--ui-base-color);
            position: absolute;
            top: 0;
            left: 0;
        }

        .progress-container:hover .progress-bg {
            height: 2px;
        }

        .time-display {
            font-variant-numeric: tabular-nums;
            opacity: 0.5;
            width: 100px;
            text-align: right;
            flex-shrink: 0;
        }

        /* Perception Metrics */
        .ai-perception {
            display: flex;
            margin-left: auto;
            flex-shrink: 0;
            align-items: center;
        }

        .ai-metric {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        .ai-metric-label {
            font-size: 8px;
            opacity: 0.5;
            margin-bottom: 2px;
        }

        #signal-canvas {
            width: 60px;
            height: 15px;
            opacity: 0.8;
        }

        /* State Modifiers */
        .active-mode #drop-zone {
            opacity: 0;
            transform: translate(-50%, -40%);
            pointer-events: none;
        }

        .active-mode footer {
            opacity: 1;
            transform: translateY(0);
        }

        /* Surgical Gradient Removal (Bottom Playback Bar Only) */
        footer {
            background: transparent !important;
            background-image: none !important;
        }

        /* --- AURA 16.6: MINIMALIST SEQUENCE CONSOLE --- */
        #playlist-trigger-zone {
            position: fixed;
            right: 0;
            top: 50%;
            transform: translateY(-50%);
            width: 50px;
            /* 极简的边缘感应宽度 */
            height: 40vh;
            /* 只占据屏幕正中间 40% 的高度，完美避开上下按钮 */
            z-index: 99;
        }

        #playlist-console {
            position: fixed;
            right: 0;
            top: 0;
            height: 100vh;
            width: 280px;
            padding: 40px 30px 40px 40px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            gap: 16px;
            z-index: 100;
            transform: translateX(100%);
            opacity: 0;
            transition: all 0.6s cubic-bezier(0.16, 1, 0.3, 1);
            pointer-events: none;
            background: linear-gradient(to left, rgba(0, 0, 0, 0.4), transparent);
        }

        #playlist-trigger-zone:hover~#playlist-console,
        #playlist-console:hover {
            transform: translateX(0);
            opacity: 1;
            pointer-events: auto;
        }

        .playlist-item {
            color: rgba(255, 255, 255, 0.3);
            font-size: 0.65rem;
            letter-spacing: 0.15em;
            cursor: pointer;
            transition: all 0.4s ease;
            text-align: right;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }

        .playlist-item:hover {
            color: rgba(255, 255, 255, 0.7);
            transform: translateX(-5px);
        }

        .playlist-item.active {
            color: #FFFFFF;
            font-weight: 400;
        }
    </style>
</head>

<body>
    <div id="playlist-trigger-zone"></div>
    <div id="playlist-console"></div>

    <div id="canvas-container"></div>

    <div id="ui-layer">
        <header>
            <div class="brand">A U R A</div>
            <div class="top-right-cluster">
                <div id="track-name" class="track-name">—</div>
                <div id="rec-tally" class="tally-light"></div>
                <div id="fullscreen-btn" class="icon-btn" title="Toggle Fullscreen">
                    <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                        <rect id="quad-1" x="4" y="4" width="7" height="7" fill="currentColor" opacity="0.3" />
                        <rect id="quad-2" x="13" y="4" width="7" height="7" fill="currentColor" opacity="0.3" />
                        <rect id="quad-3" x="4" y="13" width="7" height="7" fill="currentColor" opacity="0.3" />
                        <rect id="quad-4" x="13" y="13" width="7" height="7" fill="currentColor" opacity="0.3" />
                    </svg>
                </div>
            </div>
        </header>

        <label id="drop-zone">
            <input type="file" id="audio-upload" accept="audio/*,.json" multiple>
            <div class="play-btn-large" id="main-btn">UPLOAD AUDIO</div>
        </label>

        <footer>
            <div class="btn-container"><button class="btn" id="btn-play" disabled>Pause</button></div>
            <div class="progress-container" id="progress-container">
                <div class="progress-bg">
                    <div class="progress-bar" id="progress-bar"></div>
                </div>
            </div>
            <div class="time-display" id="time-display">0:00 / 0:00</div>

            <div class="ai-perception">
                <div class="ai-metric">
                    <span class="ai-metric-label">Signal</span>
                    <canvas id="signal-canvas" width="120" height="30"></canvas>
                </div>
            </div>

            <label style="cursor: pointer; margin-left: 12px; flex-shrink: 0; width: 60px;">
                <input type="file" id="audio-upload-footer" accept="audio/*,.json" multiple style="display:none;">
                <span class="btn">Change</span>
            </label>
        </footer>
    </div>

    <script>
        /* =========================================
           AURA CORE ENGINE v16.6
           Cinematic Trajectory Playback & Audio-Visual Synchronization
        ========================================= */

        const AudioEnv = { energy: 0, centroid: 0.5, flux: 0, roughness: 0, lux: 0, v: 0.5, hnr: 0 };
        let trajectoryData = null;

        const TargetColors = { c1: new THREE.Color(), c2: new THREE.Color() };

        // 12 Distinct Aesthetic Spaces mapped in (v, a, r)
        // 12 Distinct Aesthetic Spaces mapped in 4D (v, a, r, hnr)
        const PALETTES = [
            // Neutrals / Cinematic Greys (hnr: 0.5)
            { id: 0, name: "Deep Abyss", v: 0.1, a: 0.1, r: 0.1, h: 210, s: 0.8, l: 0.1, hnr: 0.5 },
            { id: 1, name: "Morandi Drift", v: 0.5, a: 0.1, r: 0.2, h: 40, s: 0.2, l: 0.5, hnr: 0.5 },
            // Synthwave / Washy colors (Pinks, Deep Blues, Purples) (hnr: 0.3)
            { id: 2, name: "Silent Plum", v: 0.2, a: 0.2, r: 0.3, h: 320, s: 0.5, l: 0.15, hnr: 0.3 },
            { id: 3, name: "Charcoal Void", v: 0.3, a: 0.1, r: 0.5, h: 0, s: 0.0, l: 0.15, hnr: 0.5 },
            { id: 4, name: "Corrupted Cyan", v: 0.3, a: 0.8, r: 0.8, h: 180, s: 1.0, l: 0.2, hnr: 0.3 },
            { id: 5, name: "Noise Purple", v: 0.1, a: 0.9, r: 0.9, h: 280, s: 1.0, l: 0.2, hnr: 0.3 },
            { id: 6, name: "Deep Crimson", v: 0.2, a: 0.9, r: 0.7, h: 0, s: 1.0, l: 0.3, hnr: 0.3 },
            // Organic / Acoustic / Pure nature colors (hnr: 0.8)
            { id: 7, name: "Terracotta Flare", v: 0.7, a: 0.8, r: 0.4, h: 15, s: 0.8, l: 0.5, hnr: 0.8 },
            { id: 8, name: "Brass Mustard", v: 0.8, a: 0.7, r: 0.3, h: 45, s: 0.8, l: 0.4, hnr: 0.8 },
            { id: 9, name: "Kinetic Emerald", v: 0.7, a: 0.8, r: 0.2, h: 150, s: 0.6, l: 0.4, hnr: 0.8 },
            { id: 10, name: "Lucid Sky", v: 0.8, a: 0.4, r: 0.1, h: 200, s: 0.7, l: 0.6, hnr: 0.8 },
            { id: 11, name: "Mint Breeze", v: 0.9, a: 0.5, r: 0.1, h: 160, s: 0.5, l: 0.7, hnr: 0.8 }
        ];

        const EMOTIONS = PALETTES.map(p => p.name);

        let PAL_W = new Array(12).fill(0);
        PAL_W[0] = 1.0; // Default to Deep Abyss

        const S = {
            h1: 210, s1: 0.8, l1: 0.1,
            h2: 210, s2: 0.8, l2: 0.1,
            h3: 210, s3: 0.8, l3: 0.1,
            h4: 210, s4: 0.8, l4: 0.1
        };

        const updateSIG = (frame) => {
            const ATK = 0.052;
            const REL = 0.009;

            const processEnv = (key, target) => {
                if (target > AudioEnv[key]) {
                    AudioEnv[key] += (target - AudioEnv[key]) * ATK;
                } else {
                    AudioEnv[key] += (target - AudioEnv[key]) * REL;
                }
            };

            processEnv('energy', frame.a);
            processEnv('roughness', frame.r);
            processEnv('lux', frame.lux);
            processEnv('v', frame.v);
            processEnv('centroid', frame.c || frame.v); // Fallback if processing array mismatch
            processEnv('flux', frame.flux || frame.a);
            processEnv('hnr', frame.hnr || 0);
        };

        function interpolatePalettes() {
            let weights = new Array(12).fill(0);
            let totalWeight = 0;
            let minDist = 999;
            let closestEmotion = "";

            PALETTES.forEach((p, i) => {
                const dv = p.v - AudioEnv.v;
                const da = p.a - AudioEnv.energy;
                const dr = p.r - AudioEnv.roughness;

                // 4D MIGRATION: Euclidean Distance includes HNR
                // The HNR delta is heavily multiplied (3.0) to ensure gravity strictly enforces the organic/synthetic split
                const fallbackHNR = (typeof frame !== 'undefined' && frame.hnr !== undefined) ? frame.hnr : (AudioEnv.hnr || 0);
                const dhnr = (p.hnr !== undefined ? p.hnr : 0.5) - fallbackHNR; // Default 0.5 if not found

                // AURA v16.6: 4D Euclidean Distance Engine
                let dist = Math.sqrt(dv * dv + da * da + dr * dr * 0.5 + dhnr * dhnr * 3.0);

                // Soft-max Weight
                const w = Math.pow(1.0 / (dist + 0.05), 3);
                weights[i] = w;
                totalWeight += w;

                if (dist < minDist) {
                    minDist = dist;
                    closestEmotion = p.name;
                }
            });

            // Normalize and soft-lerp over time to prevent hard-cuts (PAL_LERP = 0.018)
            const PAL_LERP = 0.018;
            for (let i = 0; i < 12; i++) {
                const targetWeight = weights[i] / totalWeight;
                PAL_W[i] += (targetWeight - PAL_W[i]) * PAL_LERP;
            }
        }

        function hslToRgb(h, s, l) {
            h /= 360;
            let r, g, b;
            if (s === 0) {
                r = g = b = l;
            } else {
                const hue2rgb = (p, q, t) => {
                    if (t < 0) t += 1;
                    if (t > 1) t -= 1;
                    if (t < 1 / 6) return p + (q - p) * 6 * t;
                    if (t < 1 / 2) return q;
                    if (t < 2 / 3) return p + (q - p) * (2 / 3 - t) * 6;
                    return p;
                };
                const q = l < 0.5 ? l * (1 + s) : l + s - l * s;
                const p = 2 * l - q;
                r = hue2rgb(p, q, h + 1 / 3);
                g = hue2rgb(p, q, h);
                b = hue2rgb(p, q, h - 1 / 3);
            }
            return { r, g, b };
        }

        function applyCinematicDegradation(h, s, l) {
            let degH = h;
            let degS = s;
            let degL = l;

            // 1. Constrain Toxic Greens (approx 80-160 degrees)
            if (degH > 80 && degH < 160) {
                let centerDist = Math.abs(degH - 120) / 40.0;
                let intensity = 1.0 - centerDist;
                // Heavily desaturate and darken to create a cinematic olive/teal
                degS *= (1.0 - 0.5 * intensity);
                degL *= (1.0 - 0.3 * intensity);
                degH += 20.0 * intensity; // Shift hue off-center
            }

            // 2. Global Neon Suppression
            degS = Math.min(0.85, degS);
            degL = Math.min(0.80, degL);
            // Protect luminance floor
            degL = Math.max(0.05, degL);

            return { h: degH, s: degS, l: degL };
        }

        function setTargetColors() {
            let bh = 0, bs = 0, bl = 0; // Blended HSL

            for (let i = 0; i < 12; i++) {
                let p = PALETTES[i];
                let w = PAL_W[i];

                // Resolve hue wrap-around issues (e.g., mixing 10 and 350)
                let h = p.h;
                if (i > 0 && Math.abs(h - bh) > 180) {
                    if (h < bh) h += 360;
                    else bh += 360;
                }

                bh += h * w;
                bs += p.s * w;
                bl += p.l * w;
            }

            bh = bh % 360;

            // 4-Layer Derivation based on BP (Blended Palette parameter)
            // Layer 1 (Base Floor) -> TargetColors.c2 (Bottom)
            S.h1 = bh;
            // Let the bottom breathe with the track's true saturation instead of crushing it.
            S.s1 = bs * 0.8;
            // Liberate the luminance from the artificial black void. Let the natural palette dictate the floor.
            S.l1 = Math.max(0.15, bl * 0.6);

            // Layer 2
            S.h2 = (bh + 15) % 360;
            S.s2 = bs * 0.6;
            S.l2 = bl * 0.5;

            // Layer 3
            S.h3 = (bh - 15 + 360) % 360;
            S.s3 = bs * 0.8;
            S.l3 = bl * 0.8;

            // Layer 4 (Shimmer / Luminous) -> TargetColors.c1 (Top)
            S.h4 = bh;
            S.s4 = Math.min(1.0, bs * 1.2 + AudioEnv.hnr * 0.2);
            // Boost overall presence by removing severe flux penalty
            S.l4 = Math.min(1.0, bl + AudioEnv.flux * 0.3);

            let topDegraded = applyCinematicDegradation(S.h4, S.s4, S.l4);
            let rgbTop = hslToRgb(topDegraded.h, topDegraded.s, topDegraded.l);
            TargetColors.c1.setRGB(rgbTop.r, rgbTop.g, rgbTop.b).convertSRGBToLinear();

            let bottomDegraded = applyCinematicDegradation(S.h1, S.s1, S.l1);
            let rgbBottom = hslToRgb(bottomDegraded.h, bottomDegraded.s, bottomDegraded.l);
            TargetColors.c2.setRGB(rgbBottom.r, rgbBottom.g, rgbBottom.b).convertSRGBToLinear();
        }

        class ValueTracker {
            constructor(min, max) { this.min = min; this.max = max; }
            normalize(val) { return Math.max(0, Math.min(1, (val - this.min) / (this.max - this.min))); }
        }

        const AudioTrackers = {
            energy: new ValueTracker(10, 90),       // RMS bounds for commercial masters to hit 1.0 (Terracotta/Mustard)
            centroid: new ValueTracker(400, 3500),  // Lower-mids mapping for Acoustic/Bossa Nova warmth
            roughness: new ValueTracker(0.01, 0.3)  // Ratio of harshness-band energy
        };

        /* =========================================
           WEBGL RENDERING PIPELINE INITIALIZATION
        ========================================= */

        const renderScene = new THREE.Scene();
        const orthographicCamera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0.1, 10);
        orthographicCamera.position.z = 1;

        const webglRenderer = new THREE.WebGLRenderer({
            antialias: true,
            alpha: true,
            precision: 'highp',
            powerPreference: "high-performance"
        });
        webglRenderer.setSize(window.innerWidth, window.innerHeight);
        webglRenderer.setClearColor(0x000000, 0);

        // --- SOTA: UNLOCK HARDWARE COLOR SPACE ---
        // Automatically utilize Display-P3 on Apple XDR displays
        webglRenderer.outputEncoding = THREE.sRGBEncoding;
        if (window.matchMedia && window.matchMedia("(color-gamut: p3)").matches) {
            // Note: colorSpace is relatively new in Three.js, but ensures the canvas tries to use full hardware gamut.
            webglRenderer.outputColorSpace = THREE.DisplayP3ColorSpace || THREE.SRGBColorSpace;
        }

        document.getElementById('canvas-container').appendChild(webglRenderer.domElement);

        const vertexShader = `
    varying vec2 vUv; 
    void main() { 
        vUv = uv; 
        gl_Position = vec4(position, 1.0); 
    }
`;

        const fragmentShader = `
            uniform float uTime; 
            uniform vec2 uResolution;
            uniform vec3 uColorTop; 
            uniform vec3 uColorBottom;
            uniform float uLux;    
            uniform float uRoughness;
            uniform float uEnergy;
            uniform float uFlux;
            uniform float uIsRecording;
            varying vec2 vUv;

            // --- 1. SOTA: Valve's Screen-Space Dither ---
            // Designed for VR and high-end displays to be absolutely invisible.
            vec3 screenSpaceDither(vec2 vScreenPos) {
                vec3 vDither = vec3(dot(vec2(171.0, 231.0), vScreenPos.xy));
                vDither.rgb = fract(vDither.rgb / vec3(103.0, 71.0, 97.0));
                return vDither;
            }

            // --- 2. SOTA: ACES Filmic Tone Mapping ---
            // Academy Color Encoding System (Hollywood Standard)
            // Distributes gradients with a filmic curve, eliminating harsh color steps.
            vec3 ACESFilm(vec3 x) {
                float a = 2.51;
                float b = 0.03;
                float c = 2.43;
                float d = 0.59;
                float e = 0.14;
                return clamp((x * (a * x + b)) / (x * (c * x + d) + e), 0.0, 1.0);
            }

            // Standard hash for organic film grain
            float hash(vec2 p) {
                vec3 p3  = fract(vec3(p.xyx) * .1031);
                p3 += dot(p3, p3.yzx + 33.33);
                return fract((p3.x + p3.y) * p3.z);
            }

            void main() {
                vec2 normalizedCoords = gl_FragCoord.xy / uResolution.xy;
                
                // --- 3. SOTA: Non-Linear Optical Easing ---
                // Linear mix causes "Mach Bands" (optical ridges). 
                // We use smoothstep to create an S-curve, optically blurring the transition for the human eye.
                float gradientFactor = smoothstep(0.0, 1.0, normalizedCoords.y);
                
                // Base vertical blend
                vec3 finalColor = mix(uColorBottom, uColorTop, gradientFactor);

                // Apply emotional luminosity
                finalColor *= uLux;
                
                // Apply ACES Filmic Tone Mapping BEFORE Gamma
                finalColor = ACESFilm(finalColor);
                
                // sRGB GAMMA CORRECTION (OETF)
                finalColor = pow(finalColor, vec3(1.0 / 2.2));
                float luma = dot(finalColor, vec3(0.299, 0.587, 0.114));
                
                // --- UNIVERSAL ADAPTIVE NOISE MASK ---
                float blackMask = smoothstep(0.005, 0.03, luma);
                
                // 35MM FILM GRAIN
                float boilSpeed = mix(5.0, 24.0, uRoughness);
                float timeFrame = floor(uTime * boilSpeed);
                float grainStrength = mix(0.025, 0.005, luma);
                // HACK: Amplify grain slightly during recording to survive codec washout
                grainStrength *= mix(1.0, 1.5, uIsRecording);
                float grain = hash(gl_FragCoord.xy + timeFrame * 17.0) - 0.5;
                finalColor += (grain * grainStrength) * blackMask;

                // --- 4. SOTA: Valve's Invisible Dither Injection ---
                vec3 dither = screenSpaceDither(gl_FragCoord.xy);
                // THE SACRIFICIAL DITHER:
                // VP9 destroys fine dither. When recording (uIsRecording == 1.0), we amplify the dither by 3.5x.
                // The codec will crush the excess noise, leaving behind a perfectly smooth, unbanded gradient in the final video.
                float ditherScale = mix(1.0, 3.5, uIsRecording);
                finalColor += (dither * ditherScale / 255.0 - (0.5 * ditherScale / 255.0)) * blackMask;

                // Cinematic Alpha Channel for Export
                float exportAlpha = smoothstep(0.02, 0.8, luma);
                exportAlpha = clamp(exportAlpha + 0.05, 0.0, 1.0);

                gl_FragColor = vec4(finalColor, exportAlpha);
            }
        `;

        const shaderMaterial = new THREE.ShaderMaterial({
            vertexShader: vertexShader,
            fragmentShader: fragmentShader,
            uniforms: {
                uTime: { value: 0 },
                uResolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
                uColorTop: { value: new THREE.Color(0x0A0A0A) },
                uColorBottom: { value: new THREE.Color(0x000000) },
                uLux: { value: 1.0 },
                uRoughness: { value: 0.0 },
                uEnergy: { value: 0.0 },
                uFlux: { value: 0.0 },
                uIsRecording: { value: 0.0 }
            }
        });

        const renderPlane = new THREE.Mesh(new THREE.PlaneGeometry(2, 2), shaderMaterial);
        renderScene.add(renderPlane);


        /* =========================================
           AUDIO ARCHITECTURE & SYNC LOGIC
        ========================================= */

        const audioPlayer = new Audio();
        let isAudioPlaying = false, isUserDragging = false;
        let audioContext, analyserNode, mediaSource;

        // --- SEAMLESS BATCH PLAYLIST TRACKERS ---
        let playlistQueue = [];
        let currentTrackIndex = 0;

        const trajectoryCache = {};
        let cacheProgressInterval = null;
        let isTransitioning = false;

        const resolvedTracks = new Set(); // Tracks successfully processed by CPU pool

        function updateGlobalRenderProgress() {
            if (typeof playlistQueue === 'undefined' || playlistQueue.length === 0) return;

            const ratio = resolvedTracks.size / playlistQueue.length;
            let state = 0;

            if (ratio >= 0.99) state = 4;
            else if (ratio >= 0.75) state = 3;
            else if (ratio >= 0.50) state = 2;
            else if (ratio > 0.0) state = 1;

            updateQuadrantProgress(state);

            // Optional Aesthetic: Add a subtle glow when the entire batch is 100% ready
            const svg = document.querySelector('#fullscreen-btn svg');
            if (svg) {
                svg.style.filter = ratio >= 0.99 ? 'drop-shadow(0px 0px 4px rgba(255,255,255,0.6))' : 'none';
                svg.style.transition = 'filter 0.5s ease';
            }
        }

        function updateQuadrantProgress(state) {
            const tl = document.getElementById('quad-1');
            const tr = document.getElementById('quad-2');
            const bl = document.getElementById('quad-3');
            const br = document.getElementById('quad-4');
            if (tr) tr.style.opacity = state >= 1 ? "1" : "0.3";
            if (br) br.style.opacity = state >= 2 ? "1" : "0.3";
            if (bl) bl.style.opacity = state >= 3 ? "1" : "0.3";
            if (tl) tl.style.opacity = state >= 4 ? "1" : "0.3";
        }

        function renderPlaylistConsole() {
            const consoleEl = document.getElementById('playlist-console');
            if (!consoleEl) return;
            consoleEl.innerHTML = '';

            if (typeof playlistQueue === 'undefined' || playlistQueue.length === 0) return;

            playlistQueue.forEach((file, index) => {
                const item = document.createElement('div');
                item.className = 'playlist-item';
                if (index === currentTrackIndex) item.classList.add('active');

                // Format: "01 — SONG NAME"
                const trackNum = String(index + 1).padStart(2, '0');
                item.innerText = `${trackNum} — ${file.name.toUpperCase()}`;

                item.onclick = () => {
                    if (index === currentTrackIndex) return;
                    console.log(`AURA: Director skipped to track ${index + 1} `);
                    currentTrackIndex = index;

                    isTransitioning = true;
                    isAudioPlaying = false;

                    // isSeamless is true to preserve visual inertia
                    initializeMedia(playlistQueue[currentTrackIndex], true);
                    renderPlaylistConsole(); // Update active highlights
                };
                consoleEl.appendChild(item);
            });
        }


        async function initializeMedia(audioFile, isSeamless = false) {
            try {
                const isAlreadyActive = document.body.classList.contains('active-mode');

                if (isAudioPlaying) {
                    audioPlayer.pause();
                    isAudioPlaying = false;
                }
                document.getElementById('btn-play').disabled = true;

                if (!isAlreadyActive) {
                    document.getElementById('canvas-container').classList.remove('revealed');
                    document.body.classList.remove('active-mode');
                }

                // Track name crossfade
                const trackNameEl = document.getElementById('track-name');
                trackNameEl.style.opacity = 0;
                setTimeout(() => {
                    trackNameEl.innerText = audioFile.name;
                    trackNameEl.style.opacity = 1;
                    renderPlaylistConsole(); // <-- INJECT HERE (Updates the active white text)
                }, 500);

                if (!isSeamless) {
                    AudioEnv.a = 0; AudioEnv.c = 0.5; AudioEnv.flux = 0; AudioEnv.r = 0;
                    AudioEnv.lux = 0; AudioEnv.v = 0.5; AudioEnv.hnr = 0;
                }

                // CRITICAL: Prevent NaN crossover
                trajectoryData = null;
                let tempTrajectory = null;

                // ZERO-LATENCY CACHE EXTRACTION
                if (trajectoryCache[audioFile.name]) {
                    tempTrajectory = await trajectoryCache[audioFile.name];
                } else {
                    console.log(`AURA: First - time analysis: ${audioFile.name} `);
                    try {
                        const formData = new FormData();
                        formData.append('file', audioFile);

                        trajectoryCache[audioFile.name] = fetch('http://localhost:5001/analyze', { method: 'POST', body: formData })
                            .then(response => {
                                if (response.ok) return response.json();
                                throw new Error("HTTP error");
                            })
                            .then(resPayload => resPayload.frames ? resPayload.frames : resPayload)
                            .catch(e => null);

                        tempTrajectory = await trajectoryCache[audioFile.name];
                    } catch (e) {
                        console.warn("Fallback to realtime.");
                    }
                }

                if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
                if (audioContext.state === 'suspended') await audioContext.resume();

                if (!analyserNode) {
                    analyserNode = audioContext.createAnalyser();
                    analyserNode.fftSize = 1024;
                    analyserNode.smoothingTimeConstant = 0.1;
                    mediaSource = audioContext.createMediaElementSource(audioPlayer);
                    mediaSource.connect(analyserNode);
                    analyserNode.connect(audioContext.destination);
                }

                audioPlayer.src = URL.createObjectURL(audioFile);

                await new Promise(resolve => {
                    audioPlayer.addEventListener('canplay', resolve, { once: true });
                });

                webglRenderer.compile(renderScene, orthographicCamera);
                document.body.classList.add('active-mode');
                document.getElementById('canvas-container').classList.add('revealed');

                // ASSIGN ONLY WHEN SAFE
                trajectoryData = tempTrajectory;

                audioPlayer.play().then(() => {
                    isAudioPlaying = true;
                    isTransitioning = false;
                    document.getElementById('btn-play').disabled = false;
                    document.getElementById('btn-play').innerText = 'Pause';
                }).catch(err => console.error(err));

            } catch (err) {
                console.error(err);
            }
        }

        function processTrajectoryFrame() {
            if (!trajectoryData || trajectoryData.length === 0) return null;
            if (!isAudioPlaying) return null;

            const currentTime = audioPlayer.currentTime;
            let frameIdx = Math.floor(currentTime * 10);

            // SANITIZED OUT-OF-BOUNDS CHECK (Prevents NaN Black Screen)
            if (frameIdx >= trajectoryData.length - 1) {
                const lastFrame = trajectoryData[trajectoryData.length - 1];
                return {
                    v: lastFrame.v !== undefined ? lastFrame.v : (lastFrame.v_top + lastFrame.v_bottom) / 2.0,
                    a: lastFrame.a,
                    r: lastFrame.r,
                    lux: lastFrame.lux,
                    c: lastFrame.c !== undefined ? lastFrame.c : lastFrame.v_top,
                    flux: lastFrame.flux !== undefined ? lastFrame.flux : lastFrame.a,
                    hnr: lastFrame.hnr !== undefined ? lastFrame.hnr : (lastFrame.sat || 0)
                };
            }

            const currentFrame = trajectoryData[frameIdx];
            const nextFrame = trajectoryData[frameIdx + 1];
            const lerpFactor = (currentTime * 10) - frameIdx;

            const currentV = currentFrame.v !== undefined ? currentFrame.v : (currentFrame.v_top + currentFrame.v_bottom) / 2.0;
            const nextV = nextFrame.v !== undefined ? nextFrame.v : (nextFrame.v_top + nextFrame.v_bottom) / 2.0;
            const currentC = currentFrame.c !== undefined ? currentFrame.c : currentFrame.v_top;
            const nextC = nextFrame.c !== undefined ? nextFrame.c : nextFrame.v_top;
            const currentFlux = currentFrame.flux !== undefined ? currentFrame.flux : currentFrame.a;
            const nextFlux = nextFrame.flux !== undefined ? nextFrame.flux : nextFrame.a;
            const currentHnr = currentFrame.hnr !== undefined ? currentFrame.hnr : (currentFrame.sat || 0);
            const nextHnr = nextFrame.hnr !== undefined ? nextFrame.hnr : (nextFrame.sat || 0);

            return {
                v: THREE.MathUtils.lerp(currentV, nextV, lerpFactor),
                a: THREE.MathUtils.lerp(currentFrame.a, nextFrame.a, lerpFactor),
                r: THREE.MathUtils.lerp(currentFrame.r, nextFrame.r, lerpFactor),
                lux: THREE.MathUtils.lerp(currentFrame.lux, nextFrame.lux, lerpFactor),
                c: THREE.MathUtils.lerp(currentC, nextC, lerpFactor),
                flux: THREE.MathUtils.lerp(currentFlux, nextFlux, lerpFactor),
                hnr: THREE.MathUtils.lerp(currentHnr, nextHnr, lerpFactor)
            };
        }

        function processRealtimeAudio() {
            if (!analyserNode || !isAudioPlaying) return;

            const freqData = new Uint8Array(analyserNode.frequencyBinCount);
            analyserNode.getByteFrequencyData(freqData);

            let sumIntensity = 0;
            let sumSquared = 0;
            let weightedSum = 0;
            let harshnessBandIntensity = 0;

            const numBins = freqData.length;
            const nyquist = audioContext.sampleRate / 2;

            // Presence Band: 2000Hz to 6000Hz
            const harshnessBinStart = Math.floor((2000 / nyquist) * numBins);
            const harshnessBinEnd = Math.floor((6000 / nyquist) * numBins);

            for (let i = 0; i < numBins; i++) {
                const amp = freqData[i];
                if (amp === 0) continue;

                // 1. Arousal: RMS based on frequency bins
                sumSquared += (amp * amp);
                sumIntensity += amp;

                // 2. Valence: Spectral Centroid
                const freq = (i / numBins) * nyquist;
                weightedSum += freq * amp;

                // 3. Roughness: Energy in the 2kHz - 6kHz presence band
                if (i >= harshnessBinStart && i <= harshnessBinEnd) {
                    harshnessBandIntensity += amp;
                }
            }

            // Calculations
            const rms = Math.sqrt(sumSquared / numBins);
            const centroid = sumIntensity > 0 ? (weightedSum / sumIntensity) : 0;
            const rRoughness = sumIntensity > 0 ? (harshnessBandIntensity / sumIntensity) : 0;

            const targetEnergy = AudioTrackers.energy.normalize(rms);
            const targetValence = AudioTrackers.centroid.normalize(centroid);
            const rNorm = AudioTrackers.roughness.normalize(rRoughness);

            return {
                a: targetEnergy,
                c: targetValence,
                v: targetValence, // Fallback for realtime
                r: rNorm,
                lux: targetEnergy,
                flux: targetEnergy, // Fallback
                hnr: targetValence // Fallback
            };
        }

        let globalTimePhase = 0;

        function renderMinimalOscilloscope() {
            if (!analyserNode || !isAudioPlaying) return;

            const canvas = document.getElementById('signal-canvas');
            const ctx = canvas.getContext('2d');
            const timeDomainData = new Uint8Array(analyserNode.fftSize);
            analyserNode.getByteTimeDomainData(timeDomainData);

            ctx.clearRect(0, 0, canvas.width, canvas.height);

            ctx.lineWidth = 1;
            ctx.strokeStyle = 'rgba(234, 234, 234, 0.6)';
            ctx.beginPath();

            const sliceWidth = canvas.width / timeDomainData.length;
            let xPos = 0;

            for (let i = 0; i < timeDomainData.length; i++) {
                const amplitude = timeDomainData[i] / 128.0;
                const yPos = amplitude * canvas.height / 2;
                if (i === 0) ctx.moveTo(xPos, yPos);
                else ctx.lineTo(xPos, yPos);
                xPos += sliceWidth;
            }
            ctx.stroke();
        }

        function animationLoop() {
            requestAnimationFrame(animationLoop);

            if (isAudioPlaying || isTransitioning) {

                // EXPONENTIAL VOLUME FADE LOGIC (2s OUT / 3s IN)
                if (isAudioPlaying && audioPlayer.duration) {
                    const timeLeft = audioPlayer.duration - audioPlayer.currentTime;
                    const timeIn = audioPlayer.currentTime;

                    if (timeLeft <= 2.0 && timeLeft > 0) {
                        const fadeRatio = timeLeft / 2.0;
                        audioPlayer.volume = Math.max(0, Math.pow(fadeRatio, 2));
                    } else if (timeIn <= 3.0) {
                        const fadeRatio = timeIn / 3.0;
                        audioPlayer.volume = Math.min(1, Math.pow(fadeRatio, 2));
                    } else {
                        audioPlayer.volume = 1.0;
                    }
                }

                let frame = null;
                if (isTransitioning) {
                    // COASTING MODE (Prevents black screen during transition)
                    AudioEnv.energy *= 0.98;
                    AudioEnv.lux = Math.max(0.40, AudioEnv.lux * 0.98); // Dim to 40%, NEVER pure black
                    AudioEnv.flux *= 0.90;
                } else if (trajectoryData && trajectoryData.length > 0) {
                    frame = processTrajectoryFrame();
                } else {
                    frame = processRealtimeAudio();
                }

                if (frame && !isTransitioning) {
                    AudioEnv.hnr = frame.hnr !== undefined ? frame.hnr : 0;
                    AudioEnv.flux = frame.flux !== undefined ? frame.flux : 0;
                    updateSIG(frame);
                }

                interpolatePalettes();
                setTargetColors();

                globalTimePhase += 0.005 + AudioEnv.energy * 0.01;

                shaderMaterial.uniforms.uColorTop.value.lerp(TargetColors.c1, 0.002);
                shaderMaterial.uniforms.uColorBottom.value.lerp(TargetColors.c2, 0.002);

                shaderMaterial.uniforms.uTime.value = globalTimePhase;
                shaderMaterial.uniforms.uLux.value = AudioEnv.lux;
                shaderMaterial.uniforms.uRoughness.value = AudioEnv.roughness;
                shaderMaterial.uniforms.uEnergy.value = AudioEnv.energy;
                shaderMaterial.uniforms.uFlux.value = AudioEnv.flux;

                if (!isTransitioning) renderMinimalOscilloscope();
                updateUserInterface();
            }

            webglRenderer.render(renderScene, orthographicCamera);
        }
        animationLoop();

        /* =========================================
           USER INTERACTION & EVENT LISTENERS
        ========================================= */

        const formatTimestamp = (seconds) => {
            if (isNaN(seconds)) return "0:00";
            const m = Math.floor(seconds / 60);
            const s = Math.floor(seconds % 60).toString().padStart(2, '0');
            return `${m}:${s} `;
        };

        function updateUserInterface() {
            if (isUserDragging || !audioPlayer.duration) return;
            const percentage = (audioPlayer.currentTime / audioPlayer.duration) * 100;
            document.getElementById('progress-bar').style.width = percentage + '%';
            document.getElementById('time-display').innerText = `${formatTimestamp(audioPlayer.currentTime)} / ${formatTimestamp(audioPlayer.duration)}`;
        }

        function togglePlaybackState() {
            if (!audioPlayer.src) return;
            if (audioPlayer.paused) {
                audioPlayer.play();
                isAudioPlaying = true;
                document.getElementById('btn-play').innerText = 'Pause';
            } else {
                audioPlayer.pause();
                isAudioPlaying = false;
                document.getElementById('btn-play').innerText = 'Play';
            }
        }

        // --- SEAMLESS RELAY TRIGGER ---
        audioPlayer.addEventListener('ended', () => {
            if (typeof playlistQueue !== 'undefined' && currentTrackIndex < playlistQueue.length - 1) {
                currentTrackIndex++;
                console.log(`AURA: Track ended. Initiating 1.5s cinematic breath...`);

                isTransitioning = true;
                isAudioPlaying = false;

                setTimeout(() => {
                    initializeMedia(playlistQueue[currentTrackIndex], true);
                }, 1500);

            } else {
                console.log("AURA Sequence Complete.");
                isAudioPlaying = false;
                document.getElementById('btn-play').innerText = 'Play';
            }
        });

        document.getElementById('btn-play').addEventListener('click', togglePlaybackState);

        window.addEventListener('keydown', (e) => {
            if (e.code === 'Space') { e.preventDefault(); togglePlaybackState(); }
        });

        document.addEventListener('click', (e) => {
            if (!e.target.closest('button, label, input, .progress-container, .header-right')) {
                document.body.classList.toggle('cursor-hidden');
            }
        });

        window.addEventListener('mousemove', () => {
            document.body.classList.remove('cursor-hidden');
        });

        document.getElementById('fullscreen-btn').addEventListener('click', () => {
            if (!document.fullscreenElement) document.documentElement.requestFullscreen();
            else if (document.exitFullscreen) document.exitFullscreen();
        });

        const progressBarContainer = document.getElementById('progress-container');
        const executeSeek = (e) => {
            const rect = progressBarContainer.getBoundingClientRect();
            const position = Math.max(0, Math.min(1, (e.clientX - rect.left) / rect.width));
            document.getElementById('progress-bar').style.width = (position * 100) + '%';
            if (audioPlayer.duration) audioPlayer.currentTime = position * audioPlayer.duration;
        };

        progressBarContainer.addEventListener('mousedown', e => { isUserDragging = true; executeSeek(e); });
        window.addEventListener('mousemove', e => { if (isUserDragging) executeSeek(e); });
        window.addEventListener('mouseup', () => { isUserDragging = false; });

        const executeFileInput = (e) => {
            playlistQueue = [];
            currentTrackIndex = 0;
            const files = e.target.files ? e.target.files : e.dataTransfer.files;

            for (let i = 0; i < files.length; i++) {
                if (files[i].type.startsWith('audio/')) {
                    playlistQueue.push(files[i]);
                }
            }
            if (playlistQueue.length > 0) {
                resolvedTracks.clear();
                updateQuadrantProgress(0);
                if (typeof renderPlaylistConsole === 'function') renderPlaylistConsole();

                // 1. Play Track 0 instantly via Realtime engine
                initializeMedia(playlistQueue[0]);

                // 2. MASS DISPATCH: Feed ALL tracks to the Concurrency Pool simultaneously
                for (let i = 0; i < playlistQueue.length; i++) {
                    const file = playlistQueue[i];

                    if (!trajectoryCache[file.name]) {
                        console.log(`AURA: [CONCURRENCY POOL] Dispatching: ${file.name}`);
                        const formData = new FormData();
                        formData.append('file', file);

                        trajectoryCache[file.name] = fetch('http://localhost:5001/analyze', { method: 'POST', body: formData })
                            .then(res => res.ok ? res.json() : null)
                            .then(data => {
                                console.log(`AURA: [CONCURRENCY POOL] Resolved -> ${file.name}`);
                                resolvedTracks.add(file.name);
                                updateGlobalRenderProgress();
                                if (typeof renderPlaylistConsole === 'function') renderPlaylistConsole();
                                return data ? (data.frames ? data.frames : data) : null;
                            })
                            .catch(e => {
                                console.warn(`AURA: Analysis Failed -> ${file.name}`);
                                resolvedTracks.add(file.name); // Add to prevent deadlocking the UI indicator
                                updateGlobalRenderProgress();
                                delete trajectoryCache[file.name];
                                return null;
                            });
                    } else {
                        // Already cached from a previous session
                        resolvedTracks.add(file.name);
                        updateGlobalRenderProgress();
                    }
                }
            }
            if (e.target.value) e.target.value = '';
        };

        document.getElementById('audio-upload').addEventListener('change', executeFileInput);
        document.getElementById('audio-upload-footer').addEventListener('change', executeFileInput);

        window.addEventListener('dragover', e => e.preventDefault());
        window.addEventListener('drop', e => {
            e.preventDefault();
            executeFileInput(e);
        });

        let cinematicRecorder;
        let recordedChunks = [];
        let isRecording = false;

        function toggleCinematicRecording() {
            const tallyLight = document.getElementById('rec-tally');

            if (!isRecording) {
                // 1. Capture pure visual WebGL buffer
                const canvas = webglRenderer.domElement;
                const videoStream = canvas.captureStream(60);

                // 2. Prepare the combined audiovisual stream
                const combinedStream = new MediaStream();

                // Add video track
                videoStream.getVideoTracks().forEach(track => combinedStream.addTrack(track));

                // 3. Audio Multiplexing (Muxing)
                // Locate your global audio element (Assuming 'audioElement', 'audio', or similar is used in initializeMedia)
                const currentAudioElement = audioPlayer;

                if (currentAudioElement) {
                    // Extract audio stream (handles cross-browser capture methods)
                    const audioCaptureNode = currentAudioElement.captureStream ? currentAudioElement.captureStream() :
                        (currentAudioElement.mozCaptureStream ? currentAudioElement.mozCaptureStream() : null);

                    if (audioCaptureNode && audioCaptureNode.getAudioTracks().length > 0) {
                        audioCaptureNode.getAudioTracks().forEach(track => combinedStream.addTrack(track));
                        console.log("AURA: Audio track successfully multiplexed.");
                    } else {
                        console.warn("AURA: Could not extract audio track. Video may be silent.");
                    }
                } else {
                    console.warn("AURA: No active audio element found for muxing.");
                }

                // 4. Force extreme bitrate (250 Mbps) to preserve dither against compression
                const options = {
                    mimeType: 'video/webm; codecs=vp9',
                    videoBitsPerSecond: 250000000
                };

                try {
                    // Initialize recorder with the COMBINED stream
                    cinematicRecorder = new MediaRecorder(combinedStream, options);
                } catch (e) {
                    console.warn("VP9 extreme bitrate failed, falling back to default:", e);
                    cinematicRecorder = new MediaRecorder(combinedStream);
                }

                cinematicRecorder.ondataavailable = (e) => {
                    if (e.data.size > 0) recordedChunks.push(e.data);
                };

                cinematicRecorder.onstop = exportCinematicMaster;

                // Turn ON Shader Sacrificial Dither to survive compression
                if (shaderMaterial) shaderMaterial.uniforms.uIsRecording.value = 1.0;

                cinematicRecorder.start();
                isRecording = true;
                tallyLight.classList.add('recording');
                console.log("AURA: Cinematic Audiovisual Recording Started (250Mbps target)...");
            } else {
                cinematicRecorder.stop();
                isRecording = false;
                tallyLight.classList.remove('recording');

                // Turn OFF Shader Sacrificial Dither
                if (shaderMaterial) shaderMaterial.uniforms.uIsRecording.value = 0.0;

                console.log("AURA: Cinematic Recording Stopped. Compiling master...");
            }
        }

        function exportCinematicMaster() {
            const blob = new Blob(recordedChunks, { type: 'video/webm' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            document.body.appendChild(a);
            a.style = 'display: none';
            a.href = url;
            a.download = `AURA_MASTER_${Date.now()}.webm`;
            a.click();
            window.URL.revokeObjectURL(url);
            recordedChunks = [];
        }

        // Bind to 'r' or 'R' keydown
        window.addEventListener('keydown', (e) => {
            if (e.key.toLowerCase() === 'r') {
                toggleCinematicRecording();
            }
        });

        window.addEventListener('resize', () => {
            if (webglRenderer) webglRenderer.setSize(window.innerWidth, window.innerHeight);
            if (shaderMaterial) shaderMaterial.uniforms.uResolution.value.set(window.innerWidth, window.innerHeight);
        });

    </script>
</body>

</html>